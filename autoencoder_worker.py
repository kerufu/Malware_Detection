import time
import random
from termcolor import cprint

import tensorflow as tf

import setting
from dataset_worker import dataset_worker

class encoder(tf.keras.Model):
    def __init__(self):
        super(encoder, self).__init__()
        self.model = [
            tf.keras.layers.Dense(128, activation='selu'),
            tf.keras.layers.Dense(63, activation='selu'),
            tf.keras.layers.Dense(32, activation='selu'),
            tf.keras.layers.Dense(setting.embedding_dimension, activity_regularizer=tf.keras.regularizers.L2(0.001))
        ]

    def call(self, x):
        for layer in self.model:
            x = layer(x)
        return x
    
class decoder(tf.keras.Model):
    def __init__(self):
        super(decoder, self).__init__()
        self.model = [
            tf.keras.layers.Dense(32, activation='selu'),
            tf.keras.layers.Dense(64, activation='selu'),
            tf.keras.layers.Dense(128, activation='selu'),
            tf.keras.layers.Dense(setting.num_embedding_variable)
        ]

    def call(self, x):
        for layer in self.model:
            x = layer(x)
        return x

class discriminator(tf.keras.Model):
    def __init__(self):
        super(discriminator, self).__init__()
        self.model = [
            tf.keras.layers.Dense(64, activation='selu'),
            tf.keras.layers.Dense(1)
        ]

    def call(self, x):
        for layer in self.model:
            x = layer(x)
        return x
    
class ae_classifier(tf.keras.Model):
    def __init__(self):
        super(ae_classifier, self).__init__()
        self.model = [
            tf.keras.layers.Dense(64, activation='selu'),
            tf.keras.layers.Dense(1)
        ]

    def call(self, x):
        for layer in self.model:
            x = layer(x)
        return x
    
class autoencoder_woker():
    
    def __init__(self, enable_discriminator=False, ae_iteration=1, c_iteration=1, dis_iteration=1):
        self.enable_discriminator = enable_discriminator
        self.ae_iteration = ae_iteration
        self.c_iteration = c_iteration
        self.dis_iteration = dis_iteration

        self.e = encoder()
        self.d = decoder()
        self.c = ae_classifier()
        if self.enable_discriminator:
            self.dis = discriminator()
        try:
            self.e.load_weights(setting.encoder_path)
            self.d.load_weights(setting.decoder_path)
            self.c.load_weights(setting.ae_classifier_path)
            if self.enable_discriminator:
                self.dis.load_weights(setting.discriminator_path)
            print("Saved audoencoder weight loaded")
        except:
            print("Saved audoencoder weight not found")

        self.encoder_optimizer = tf.keras.optimizers.Adam(clipnorm=1.0)
        self.decoder_optimizer = tf.keras.optimizers.Adam(clipnorm=1.0)
        self.classifier_optimizer = tf.keras.optimizers.Adam(clipnorm=1.0)
        if self.enable_discriminator:
            self.discriminator_optimizer = tf.keras.optimizers.Adam(clipnorm=1.0)

        self.reconstruction_loss = tf.keras.losses.MeanSquaredError()
        self.classifying_loss = tf.keras.losses.BinaryFocalCrossentropy(from_logits=True)
        if self.enable_discriminator:
            self.discriminator_loss = tf.keras.losses.BinaryFocalCrossentropy(from_logits=True)

        self.train_ae_metric = tf.keras.metrics.MeanSquaredError()
        self.test_ae_metric = tf.keras.metrics.MeanSquaredError()
        self.train_c_metric = tf.keras.metrics.BinaryAccuracy()
        self.test_c_metric = tf.keras.metrics.BinaryAccuracy()
        if self.enable_discriminator:
            self.train_d_metric = tf.keras.metrics.BinaryAccuracy()
            self.test_d_metric = tf.keras.metrics.BinaryAccuracy()

    @tf.function
    def train_step(self, batch):
        embedding, non_embedding, label = batch["e"], batch["n"], batch["l"]
        for _ in range(self.ae_iteration):
            with tf.GradientTape() as e_tape:
                with tf.GradientTape() as d_tape:
                    features = self.e(embedding, training=True)
                    decoder_output = self.d(features, training=True)
                
                    r_loss = self.reconstruction_loss(embedding, decoder_output)
                    e_loss = r_loss
                    self.train_ae_metric.update_state(embedding, decoder_output)

                    c_output = self.c(tf.concat([features, non_embedding], 1), training=True)
                    e_loss += setting.ae_classifier_weight * self.classifying_loss(label, c_output)

                    if self.enable_discriminator:
                        dis_output = self.dis(features, training=True)
                        e_loss += setting.discriminator_weight * self.discriminator_loss(tf.ones_like(dis_output), dis_output)

                    gradients_of_e = e_tape.gradient(e_loss, self.e.trainable_variables)
                    self.encoder_optimizer.apply_gradients(zip(gradients_of_e, self.e.trainable_variables))

                    gradients_of_d = d_tape.gradient(r_loss, self.d.trainable_variables)
                    self.decoder_optimizer.apply_gradients(zip(gradients_of_d, self.d.trainable_variables))

        for _ in range(self.ae_iteration):
            with tf.GradientTape() as c_tape:
                features = self.e(embedding, training=True)
                c_output = self.c(tf.concat([features, non_embedding], 1), training=True)
                c_loss = self.classifying_loss(label, c_output)

                gradients_of_c = c_tape.gradient(c_loss, self.c.trainable_variables)
                self.classifier_optimizer.apply_gradients(zip(gradients_of_c, self.c.trainable_variables))

                self.train_c_metric.update_state(label, c_output)
        
        if self.enable_discriminator:
            for _ in range(self.dis_iteration):
                with tf.GradientTape() as dis_tape:
                    features = self.e(embedding, training=True)
                    noise = tf.random.normal([setting.batch_size, setting.embedding_dimension])
                    noise_output = self.dis(noise, training=True)
                    encoded_output = self.dis(features, training=True)

                    dis_loss = self.discriminator_loss(tf.ones_like(noise_output), noise_output)
                    dis_loss += self.discriminator_loss(tf.zeros_like(encoded_output), encoded_output)
                    self.train_d_metric.update_state(tf.ones_like(noise_output), noise_output)
                    self.train_d_metric.update_state(tf.zeros_like(encoded_output), encoded_output)

                    gradients_of_dis = dis_tape.gradient(dis_loss, self.dis.trainable_variables)
                    self.discriminator_optimizer.apply_gradients(zip(gradients_of_dis, self.dis.trainable_variables))

        return decoder_output

    @tf.function
    def test_step(self, batch):
        embedding, non_embedding, label = batch["e"], batch["n"], batch["l"]
        features = self.e(embedding, training=False)
        decoder_output = self.d(features, training=False)
        self.test_ae_metric.update_state(embedding, decoder_output)

        c_output = self.c(tf.concat([features, non_embedding], 1), training=True)
        self.test_c_metric.update_state(label, c_output)

        if self.enable_discriminator:
            noise = tf.random.normal([setting.batch_size, setting.embedding_dimension])
            noise_output = self.dis(noise, training=False)
            encoded_output = self.dis(features, training=False)
            
            self.test_d_metric.update_state(tf.ones_like(noise_output), noise_output)
            self.test_d_metric.update_state(tf.zeros_like(encoded_output), encoded_output)
        
        return decoder_output

    def train(self, epochs=1, load_from_raw=False):

        dsw = dataset_worker()
        dsw.dataset_loader(load_from_raw)
        embedding_data = dsw.get_embedding_data()
        non_embedding_data = dsw.get_non_embedding_data()

        legitimate_lable = non_embedding_data[:,-1].astype(int)
        
        full_dataset = tf.data.Dataset.from_tensor_slices({"e": embedding_data, "n": tf.cast(non_embedding_data[:,:-1], tf.float32), "l": legitimate_lable})
        full_dataset = full_dataset.shuffle(setting.dataset_size, reshuffle_each_iteration=True)
        full_dataset = full_dataset.batch(setting.batch_size)

        train_dataset = full_dataset.take(setting.train_dataset_size)
        test_dataset = full_dataset.skip(setting.train_dataset_size)

        for epoch in range(epochs):
            start = time.time()
            for batch in train_dataset:
                train_input = batch["e"]
                train_output = self.train_step(batch)
            for batch in test_dataset:
                test_input = batch["e"]
                test_output = self.test_step(batch)
                
            cprint('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start), 'red')

            print("Train AutoEncoder Loss:" + str(self.train_ae_metric.result().numpy()))
            print("Test AutoEncoder Loss:" + str(self.test_ae_metric.result().numpy()))

            tf.print("Train True Sample: ", train_input[0, :])
            tf.print("Train Decoded Sample: ", train_output[0, :])

            tf.print("Test True Sample: ", test_input[0, :])
            tf.print("Test Decoded Sample: ", test_output[0, :])

            print("Train Classifier Accuracy:" + str(self.train_c_metric.result().numpy()))
            print("Test Classifier Accuracy:" + str(self.test_c_metric.result().numpy()))

            if self.enable_discriminator:
                print("Train Discriminator Accuracy:" + str(self.train_d_metric.result().numpy()))
                print("Test Discriminator Accuracy:" + str(self.test_d_metric.result().numpy()))

            self.e.save(setting.encoder_path)
            self.d.save(setting.decoder_path)
            self.c.save(setting.ae_classifier_path)
            if self.enable_discriminator:
                self.dis.save(setting.discriminator_path)

    def test(self, load_from_raw=False):

        dsw = dataset_worker()
        dsw.dataset_loader(load_from_raw)
        indexes = [random.randint(0, setting.dataset_size-1) for _ in range(setting.test_dataset_size)]
        embedding_data = dsw.get_embedding_data()[indexes]
        non_embedding_data = dsw.get_non_embedding_data()[indexes]
        legitimate_lable = non_embedding_data[:,-1].astype(int)
        non_embedding_data = non_embedding_data[:,:-1]

        features = self.e(embedding_data, training=False)
        decoder_output = self.d(features, training=False)
        self.test_ae_metric.update_state(embedding_data, decoder_output)

        c_output = self.c(tf.concat([features, non_embedding_data], 1), training=True)
        self.test_c_metric.update_state(legitimate_lable, c_output)

        if self.enable_discriminator:
            noise = tf.random.normal([setting.test_dataset_size, setting.embedding_dimension])
            noise_output = self.dis(noise, training=False)
            encoded_output = self.dis(features, training=False)
            
            self.test_d_metric.update_state(tf.ones_like(noise_output), noise_output)
            self.test_d_metric.update_state(tf.zeros_like(encoded_output), encoded_output)

        embedding_sample = embedding_data[random.randint(0, setting.test_dataset_size-1), :]
        embedding_sample = tf.reshape(embedding_sample,shape=(1, setting.num_embedding_variable))
        sample_features = self.e(embedding_sample, training=False)
        decoded_sample = self.d(sample_features, training=False)

        print("Test AutoEncoder Loss:" + str(self.test_ae_metric.result().numpy()))
        tf.print("Test True Sample: ", embedding_sample)
        tf.print("Test Decoded Sample: ", decoded_sample)
        print("Test Classifier Accuracy:" + str(self.test_c_metric.result().numpy()))
        if self.enable_discriminator:
            print("Test Discriminator Accuracy:" + str(self.test_d_metric.result().numpy()))
    