import time

import tensorflow as tf

import setting
from dataset_worker import dataset_worker

class encoder(tf.keras.Model):
    def __init__(self):
        super(encoder, self).__init__()
        self.model = [
            tf.keras.layers.Dense(64, activation='relu'),
            tf.keras.layers.Dense(16, activation='sigmoid', activity_regularizer=tf.keras.regularizers.L2(0.01))
        ]

    def call(self, x):
        for layer in self.model:
            x = layer(x)
        return x
    
class decoder(tf.keras.Model):
    def __init__(self):
        super(decoder, self).__init__()
        self.model = [
            tf.keras.layers.Dense(64, activation='relu'),
            tf.keras.layers.Dense(setting.num_embedding_variable, activation='relu')
        ]

    def call(self, x):
        for layer in self.model:
            x = layer(x)
        return x
    
class embedding_woker():
    
    def __init__(self):
        self.e = encoder()
        self.d = decoder()
        try:
            self.e.load_weights(setting.encoder_path)
            self.d.load_weights(setting.decoder_path)
            print("Saved embedding weight loaded")
        except:
            pass
        self.encoder_optimizer = tf.keras.optimizers.Adam()
        self.decoder_optimizer = tf.keras.optimizers.Adam()

        self.reconstruction_loss = tf.keras.losses.MeanSquaredError()

        self.train_metric = tf.keras.metrics.MeanSquaredError()
        self.test_metric = tf.keras.metrics.MeanSquaredError()

    @tf.function
    def train_step(self, input):
        with tf.GradientTape() as e_tape:
            with tf.GradientTape() as d_tape:
                features = self.e(input, training=True)
                output = self.d(features, training=True)
            
                r_loss = self.reconstruction_loss(input, output)
                self.train_metric.update_state(input, output)

                gradients_of_e = e_tape.gradient(r_loss, self.e.trainable_variables)
                self.encoder_optimizer.apply_gradients(zip(gradients_of_e, self.e.trainable_variables))

                gradients_of_d = d_tape.gradient(r_loss, self.d.trainable_variables)
                self.decoder_optimizer.apply_gradients(zip(gradients_of_d, self.d.trainable_variables))
        
    
    @tf.function
    def test_step(self, input):
        features = self.e(input, training=False)
        output = self.d(features, training=False)
        self.test_metric.update_state(input, output)

    def train(self, epochs=1):

        dsw = dataset_worker()
        embedding_data = dsw.get_embedding_data()

        full_dataset = tf.data.Dataset.from_tensor_slices(embedding_data)
        full_dataset = full_dataset.shuffle(setting.dataset_size, reshuffle_each_iteration=True)
        full_dataset = full_dataset.batch(setting.batch_size)

        train_dataset = full_dataset.take(setting.train_dataset_size)
        test_dataset = full_dataset.skip(setting.train_dataset_size)

        for epoch in range(epochs):
            start = time.time()
            for batch in train_dataset:
                self.train_step(batch)
            for batch in test_dataset:
                self.test_step(batch)
                
            print('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))
            print("Train Loss:" + str(self.train_metric.result().numpy()))
            print("Test Loss:" + str(self.test_metric.result().numpy()))
            self.e.save(setting.encoder_path)
            self.d.save(setting.decoder_path)

    def embedding(self, input):
        return self.e.predict(input)



    

