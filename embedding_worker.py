import time

import tensorflow as tf

import setting
from dataset_worker import dataset_worker

class encoder(tf.keras.Model):
    def __init__(self):
        super(encoder, self).__init__()
        self.model = [
            tf.keras.layers.Dense(64, activation='relu'),
            tf.keras.layers.Dense(setting.embedding_dimension, activation='sigmoid', activity_regularizer=tf.keras.regularizers.L2(0.01))
        ]

    def call(self, x):
        for layer in self.model:
            x = layer(x)
        return x
    
class decoder(tf.keras.Model):
    def __init__(self):
        super(decoder, self).__init__()
        self.model = [
            tf.keras.layers.Dense(64, activation='relu'),
            tf.keras.layers.Dense(setting.num_embedding_variable)
        ]

    def call(self, x):
        for layer in self.model:
            x = layer(x)
        return x

class discriminator(tf.keras.Model):
    def __init__(self):
        super(discriminator, self).__init__()
        self.model = [
            tf.keras.layers.Dense(64, activation='relu'),
            tf.keras.layers.Dense(1, activation='sigmoid')
        ]

    def call(self, x):
        for layer in self.model:
            x = layer(x)
        return x
    
class embedding_woker():
    
    def __init__(self, enable_discriminator=False, ae_iteration=1, dis_iteration=1):
        self.enable_discriminator = enable_discriminator
        self.ae_iteration = ae_iteration
        self.dis_iteration = dis_iteration

        self.e = encoder()
        self.d = decoder()
        if self.enable_discriminator:
            self.dis = discriminator()
        try:
            self.e.load_weights(setting.encoder_path)
            self.d.load_weights(setting.decoder_path)
            if self.enable_discriminator:
                self.dis.load_weights(setting.discriminator_path)
            print("Saved embedding weight loaded")
        except:
            print("Saved embedding weight not found")

        self.encoder_optimizer = tf.keras.optimizers.Adam()
        self.decoder_optimizer = tf.keras.optimizers.Adam()
        if self.enable_discriminator:
            self.discriminator_optimizer = tf.keras.optimizers.Adam()

        self.reconstruction_loss = tf.keras.losses.MeanSquaredError()
        if self.enable_discriminator:
            self.discriminator_loss = tf.keras.losses.BinaryCrossentropy()

        self.train_mse_metric = tf.keras.metrics.MeanSquaredError()
        self.test_mse_metric = tf.keras.metrics.MeanSquaredError()
        self.reconstruction_example = tf.keras.metrics.Mean()
        if self.enable_discriminator:
            self.train_bce_metric = tf.keras.metrics.BinaryAccuracy()
            self.test_bce_metric = tf.keras.metrics.BinaryAccuracy()

    @tf.function
    def train_step(self, input):
        for _ in range(self.ae_iteration):
            with tf.GradientTape() as e_tape:
                with tf.GradientTape() as d_tape:
                    features = self.e(input, training=True)
                    output = self.d(features, training=True)
                
                    r_loss = self.reconstruction_loss(input, output)
                    e_loss = r_loss
                    self.train_mse_metric.update_state(input, output)

                    if self.enable_discriminator:
                        dis_output = self.dis(features, training=True)
                        e_loss += setting.discriminator_weight * self.discriminator_loss(tf.ones_like(dis_output), dis_output)

                    gradients_of_e = e_tape.gradient(e_loss, self.e.trainable_variables)
                    self.encoder_optimizer.apply_gradients(zip(gradients_of_e, self.e.trainable_variables))

                    gradients_of_d = d_tape.gradient(r_loss, self.d.trainable_variables)
                    self.decoder_optimizer.apply_gradients(zip(gradients_of_d, self.d.trainable_variables))
        
        if self.enable_discriminator:
            for _ in range(self.dis_iteration):
                with tf.GradientTape() as dis_tape:
                    features = self.e(input, training=True)
                    noise = tf.random.uniform([setting.batch_size, setting.embedding_dimension])
                    noise_output = self.dis(noise, training=True)
                    encoded_output = self.dis(features, training=True)

                    dis_loss = self.discriminator_loss(tf.ones_like(noise_output), noise_output)
                    dis_loss += self.discriminator_loss(tf.zeros_like(encoded_output), encoded_output)
                    self.train_bce_metric.update_state(tf.ones_like(noise_output), noise_output)
                    self.train_bce_metric.update_state(tf.zeros_like(encoded_output), encoded_output)

                    gradients_of_dis = dis_tape.gradient(dis_loss, self.dis.trainable_variables)
                    self.discriminator_optimizer.apply_gradients(zip(gradients_of_dis, self.dis.trainable_variables))

    
    @tf.function
    def test_step(self, input):
        features = self.e(input, training=False)
        output = self.d(features, training=False)
        self.test_mse_metric.update_state(input, output)

        self.reconstruction_example.update_state

        if self.enable_discriminator:
            noise = tf.random.uniform([setting.batch_size, setting.embedding_dimension])
            noise_output = self.dis(noise, training=False)
            encoded_output = self.dis(features, training=False)
            
            self.test_bce_metric.update_state(tf.ones_like(noise_output), noise_output)
            self.test_bce_metric.update_state(tf.zeros_like(encoded_output), encoded_output)
        
        return output

    def train(self, epochs=1, load_from_raw=False):

        dsw = dataset_worker(load_from_raw)
        embedding_data = dsw.get_embedding_data()

        full_dataset = tf.data.Dataset.from_tensor_slices(embedding_data)
        full_dataset = full_dataset.shuffle(setting.dataset_size, reshuffle_each_iteration=True)
        full_dataset = full_dataset.batch(setting.batch_size)

        train_dataset = full_dataset.take(setting.train_dataset_size)
        test_dataset = full_dataset.skip(setting.train_dataset_size)

        for epoch in range(epochs):
            start = time.time()
            for batch in train_dataset:
                self.train_step(batch)
            for batch in test_dataset:
                output = self.test_step(batch)
                
            print('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))
            print("Train AutoEncoder Loss:" + str(self.train_mse_metric.result().numpy()))
            print("Test AutoEncoder Loss:" + str(self.test_mse_metric.result().numpy()))

            tf.print("True Sample: ", tf.reduce_mean(batch, 0))
            tf.print("Decoded Sample: ", tf.reduce_mean(output, 0))

            if self.enable_discriminator:
                print("Train Discriminator Accuracy:" + str(self.train_bce_metric.result().numpy()))
                print("Test Discriminator Accuracy:" + str(self.test_bce_metric.result().numpy()))
            self.e.save(setting.encoder_path)
            self.d.save(setting.decoder_path)
            if self.enable_discriminator:
                self.dis.save(setting.discriminator_path)

    def embedding(self, input):
        return self.e.predict(input)
    
    def reconstruct(self, input):
        return self.d.predict(input)



    

