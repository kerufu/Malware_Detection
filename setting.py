# dataset
database_path = "dataset/data.csv"
processed_data_path = ["dataset/processed_data/non_embedding_data",
                       "dataset/processed_data/embedding_data"]
embedding_variable = [
    'SizeOfCode', 'SizeOfInitializedData', 'SizeOfUninitializedData', 'AddressOfEntryPoint', 'BaseOfCode', 'BaseOfData', 'ImageBase',
    'SizeOfImage', 'SectionsMeanEntropy', 'SectionsMinEntropy', 'SectionsMaxEntropy', 'SectionsMeanRawsize', 'SectionsMinRawsize', 'SectionMaxRawsize',
    'SectionsMeanVirtualsize', 'SectionsMinVirtualsize', 'SectionMaxVirtualsize', 'ImportsNb', 'ImportsNbOrdinal',
    'ExportNb', 'ResourcesNb', 'ResourcesMeanEntropy', 'ResourcesMinEntropy', 'ResourcesMaxEntropy', 'ResourcesMeanSize', 'ResourcesMinSize',
    'ResourcesMaxSize',
]
non_embedding_variable = [
    'Machine', 'SizeOfOptionalHeader', 'Characteristics',
    'MajorLinkerVersion', 'MinorLinkerVersion',
    'SectionAlignment', 'FileAlignment', 'MajorOperatingSystemVersion',
    'MinorOperatingSystemVersion', 'MajorImageVersion', 'MinorImageVersion',
    'MajorSubsystemVersion', 'MinorSubsystemVersion',
    'SizeOfHeaders', 'Subsystem', 'DllCharacteristics',
    'SizeOfStackReserve', 'SizeOfStackCommit', 'SizeOfHeapReserve',
    'SizeOfHeapCommit', 'LoaderFlags', 'NumberOfRvaAndSizes', 'SectionsNb',
    'ImportsNbDLL', 'LoadConfigurationSize',
    'VersionInformationSize', 'legitimate'
]
num_embedding_variable = 27
dataset_size = 138047

# overall tarining
embedding_dimension = 16
batch_size = 50
train_dataset_size = int(dataset_size*0.8/batch_size)

# embedding training
encoder_path = "saved_model/embedding/encoder"
decoder_path = "saved_model/embedding/decoder"
discriminator_path = "saved_model/embedding/discriminator"
discriminator_weight = 0.5

# classifying training
classifier_path = "saved_model/classifier"
